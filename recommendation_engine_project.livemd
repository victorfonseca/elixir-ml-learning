<!-- livebook:{"persist_outputs":true} -->

# Recommendation Engine Project

```elixir
Mix.install([
  {:nx, "~> 0.7"},
  {:axon, "~> 0.6"},
  {:explorer, "~> 0.8"},
  {:kino, "~> 0.13"},
  {:vega_lite, "~> 0.1"},
  {:httpoison, "~> 2.2"},
  {:csv, "~> 3.2"}
])

alias Explorer.DataFrame
alias Explorer.Series
alias VegaLite, as: Vl

defmodule DataLoader do
  def download_movielens_small do
    url = "https://files.grouplens.org/datasets/movielens/ml-latest-small.zip"
    {:ok, %{body: body}} = HTTPoison.get(url)
    
    {:ok, files} = :zip.unzip(body, [:memory])
    
    ratings_csv = Enum.find_value(files, fn {name, content} ->
      name = to_string(name)
      if String.ends_with?(name, "ratings.csv"), do: content
    end)
    
    ratings_csv
  end
end

# Download and load the dataset
ratings_csv = DataLoader.download_movielens_small()
ratings_df = DataFrame.load_csv!(ratings_csv)

# Display the first few rows
IO.inspect(DataFrame.head(ratings_df), label: "First few rows of ratings")

# Print some information about the dataset
IO.puts("Number of rows: #{DataFrame.n_rows(ratings_df)}")
IO.puts("Number of columns: #{DataFrame.n_columns(ratings_df)}")
IO.inspect(DataFrame.names(ratings_df), label: "Column names")
```

## Preprocessing Data

```elixir
# Preprocess the data
users = DataFrame.pull(ratings_df, "userId")
movies = DataFrame.pull(ratings_df, "movieId")
ratings = DataFrame.pull(ratings_df, "rating")

n_users = users |> Series.distinct() |> Series.count()
n_movies = movies |> Series.distinct() |> Series.count()

# Convert to tensors
x_users = Nx.tensor(Series.to_list(users))
x_movies = Nx.tensor(Series.to_list(movies))
y_ratings = Nx.tensor(Series.to_list(ratings))

# Print some information about the preprocessed data
IO.puts("Number of unique users: #{n_users}")
IO.puts("Number of unique movies: #{n_movies}")
IO.puts("Shape of x_users tensor: #{inspect(Nx.shape(x_users))}")
IO.puts("Shape of x_movies tensor: #{inspect(Nx.shape(x_movies))}")
IO.puts("Shape of y_ratings tensor: #{inspect(Nx.shape(y_ratings))}")
```

<!-- livebook:{"output":true} -->

```
Number of unique users: 610
Number of unique movies: 9724
Shape of x_users tensor: {100836}
Shape of x_movies tensor: {100836}
Shape of y_ratings tensor: {100836}
```

<!-- livebook:{"output":true} -->

```
:ok
```

## Training and testing sets data

```elixir
# Split the data into training and testing sets
train_ratio = 0.8
train_size = floor(Nx.size(x_users) * train_ratio)

{x_users_train, x_users_test} = Nx.split(x_users, train_size)
{x_movies_train, x_movies_test} = Nx.split(x_movies, train_size)
{y_ratings_train, y_ratings_test} = Nx.split(y_ratings, train_size)

# Print information about the split
IO.puts("Shape of x_users_train: #{inspect(Nx.shape(x_users_train))}")
IO.puts("Shape of x_users_test: #{inspect(Nx.shape(x_users_test))}")
IO.puts("Shape of x_movies_train: #{inspect(Nx.shape(x_movies_train))}")
IO.puts("Shape of x_movies_test: #{inspect(Nx.shape(x_movies_test))}")
IO.puts("Shape of y_ratings_train: #{inspect(Nx.shape(y_ratings_train))}")
IO.puts("Shape of y_ratings_test: #{inspect(Nx.shape(y_ratings_test))}")
```

<!-- livebook:{"output":true} -->

```
Shape of x_users_train: {80668}
Shape of x_users_test: {20168}
Shape of x_movies_train: {80668}
Shape of x_movies_test: {20168}
Shape of y_ratings_train: {80668}
Shape of y_ratings_test: {20168}
```

<!-- livebook:{"output":true} -->

```
:ok
```

## Prepare Data

```elixir
# Prepare the data
users = DataFrame.pull(ratings_df, "userId")
movies = DataFrame.pull(ratings_df, "movieId")
ratings = DataFrame.pull(ratings_df, "rating")

n_users = users |> Series.distinct() |> Series.count()
n_movies = movies |> Series.distinct() |> Series.count()

# Convert to tensors
x_users = Nx.tensor(Series.to_list(users))
x_movies = Nx.tensor(Series.to_list(movies))
y_ratings = Nx.tensor(Series.to_list(ratings))

# Print some information
IO.puts("Number of unique users: #{n_users}")
IO.puts("Number of unique movies: #{n_movies}")
IO.puts("Shape of ratings tensor: #{inspect(Nx.shape(y_ratings))}")
```

<!-- livebook:{"output":true} -->

```
Number of unique users: 610
Number of unique movies: 9724
Shape of ratings tensor: {100836}
```

<!-- livebook:{"output":true} -->

```
:ok
```

## Matrix Model

```elixir
# Create mappings for user IDs and movie IDs
user_id_map = users |> Series.distinct() |> Series.to_list() |> Enum.with_index() |> Map.new()
movie_id_map = movies |> Series.distinct() |> Series.to_list() |> Enum.with_index() |> Map.new()

n_users = map_size(user_id_map)
n_movies = map_size(movie_id_map)

IO.puts("Number of unique users: #{n_users}")
IO.puts("Number of unique movies: #{n_movies}")


defmodule MatrixFactorization do
  import Nx.Defn

  def init_params(n_users, n_movies, n_factors) do
    user_factors = random_tensor({n_users, n_factors}, 1.0)
    movie_factors = random_tensor({n_movies, n_factors}, 1.0)
    {user_factors, movie_factors}
  end

  def random_tensor(shape, scale) do
    size = Tuple.product(shape)
    data = for _ <- 1..size, do: (:rand.uniform() - 0.5) * scale
    Nx.tensor(data, type: {:f, 32}) |> Nx.reshape(shape)
  end

  defn predict({user_factors, movie_factors}, user_ids, movie_ids) do
    users = Nx.take(user_factors, user_ids)
    movies = Nx.take(movie_factors, movie_ids)
    Nx.sum(users * movies, axes: [1])
  end

  defn loss({user_factors, movie_factors}, user_ids, movie_ids, ratings, lambda) do
    pred = predict({user_factors, movie_factors}, user_ids, movie_ids)
    mse = Nx.mean(Nx.pow(pred - ratings, 2))
    reg = lambda * (Nx.sum(Nx.pow(user_factors, 2)) + Nx.sum(Nx.pow(movie_factors, 2)))
    mse + reg
  end

  defn update({user_factors, movie_factors}, user_ids, movie_ids, ratings, lr, lambda) do
    grad = grad({user_factors, movie_factors}, &loss(&1, user_ids, movie_ids, ratings, lambda))
    {
      user_factors - lr * elem(grad, 0),
      movie_factors - lr * elem(grad, 1)
    }
  end
end

```

<!-- livebook:{"output":true} -->

```
Number of unique users: 610
Number of unique movies: 9724
```

<!-- livebook:{"output":true} -->

```
{:module, MatrixFactorization, <<70, 79, 82, 49, 0, 0, 22, ...>>, true}
```

## Model Train

```elixir
# Data Preprocessing
user_id_list = users |> Series.distinct() |> Series.to_list()
movie_id_list = movies |> Series.distinct() |> Series.to_list()

user_id_map = Enum.with_index(user_id_list) |> Map.new(fn {id, index} -> {id, index} end)
movie_id_map = Enum.with_index(movie_id_list) |> Map.new(fn {id, index} -> {id, index} end)

n_users = map_size(user_id_map)
n_movies = map_size(movie_id_map)

# Convert to tensors using the mappings
x_users = Nx.tensor(Enum.map(Series.to_list(users), &Map.get(user_id_map, &1)))
x_movies = Nx.tensor(Enum.map(Series.to_list(movies), &Map.get(movie_id_map, &1)))

# Normalize ratings to [0, 1] range
{min_rating, max_rating} = Enum.min_max(Series.to_list(ratings))
y_ratings = Nx.tensor(Enum.map(Series.to_list(ratings), fn r -> (r - min_rating) / (max_rating - min_rating) end))

# Model parameters
n_factors = 50
initial_learning_rate = 0.2
decay_rate = 0.95
n_epochs = 50
batch_size = 8192
lambda = 0.01  # L2 regularization strength

# Use full dataset instead of sampling
x_users_train = x_users
x_movies_train = x_movies
y_ratings_train = y_ratings

# Initialize model
params = MatrixFactorization.init_params(n_users, n_movies, n_factors)

# Training loop with learning rate decay
final_params = Enum.reduce(1..n_epochs, params, fn epoch, current_params ->
  current_lr = initial_learning_rate * :math.pow(decay_rate, epoch - 1)
  
  {total_loss, batch_count, new_params} =
    Enum.reduce(0..(Nx.size(x_users_train) - 1)//batch_size, {Nx.tensor(0.0), 0, current_params}, fn i, {acc_loss, acc_count, params} ->
      batch_size = min(batch_size, Nx.size(x_users_train) - i)
      batch_users = Nx.slice(x_users_train, [i], [batch_size])
      batch_movies = Nx.slice(x_movies_train, [i], [batch_size])
      batch_ratings = Nx.slice(y_ratings_train, [i], [batch_size])
      
      new_params = MatrixFactorization.update(params, batch_users, batch_movies, batch_ratings, current_lr, lambda)
      loss = MatrixFactorization.loss(new_params, batch_users, batch_movies, batch_ratings, lambda)
      {Nx.add(acc_loss, loss), acc_count + 1, new_params}
    end)

  avg_loss = Nx.to_number(Nx.divide(total_loss, batch_count))
  IO.puts("Epoch #{epoch}, Average Loss: #{avg_loss}, Learning Rate: #{current_lr}")
  
  new_params
end)

IO.puts("Training completed!")

# Evaluate on full dataset
full_loss = MatrixFactorization.loss(final_params, x_users, x_movies, y_ratings, lambda)
IO.puts("Full Dataset Loss: #{Nx.to_number(full_loss)}")

# Function to make predictions
predict_rating = fn user_id, movie_id ->
  user_index = Map.get(user_id_map, user_id)
  movie_index = Map.get(movie_id_map, movie_id)
  prediction = MatrixFactorization.predict(final_params, Nx.tensor([user_index]), Nx.tensor([movie_index]))
  denormalized = Nx.multiply(prediction, max_rating - min_rating) |> Nx.add(min_rating)
  Nx.to_number(Nx.squeeze(denormalized))
end

# Example predictions
IO.puts("Example predictions:")
IO.puts("User #{Enum.at(user_id_list, 0)}, Movie #{Enum.at(movie_id_list, 0)}: #{predict_rating.(Enum.at(user_id_list, 0), Enum.at(movie_id_list, 0))}")
IO.puts("User #{Enum.at(user_id_list, 0)}, Movie #{Enum.at(movie_id_list, 99)}: #{predict_rating.(Enum.at(user_id_list, 0), Enum.at(movie_id_list, 99))}")
IO.puts("User #{Enum.at(user_id_list, 99)}, Movie #{Enum.at(movie_id_list, 0)}: #{predict_rating.(Enum.at(user_id_list, 99), Enum.at(movie_id_list, 0))}")

```

<!-- livebook:{"output":true} -->

```
Epoch 1, Average Loss: 408.0029296875, Learning Rate: 0.2
Epoch 2, Average Loss: 368.6095275878906, Learning Rate: 0.19
Epoch 3, Average Loss: 334.7301330566406, Learning Rate: 0.1805
Epoch 4, Average Loss: 305.4458312988281, Learning Rate: 0.171475
Epoch 5, Average Loss: 280.0125427246094, Learning Rate: 0.16290125
Epoch 6, Average Loss: 257.82366943359375, Learning Rate: 0.15475618749999998
Epoch 7, Average Loss: 238.38201904296875, Learning Rate: 0.14701837812499996
```

## Visualizations using VegaLite

```elixir
# Function to get top N recommendations
get_top_n_recommendations = fn user_id, n ->
  movie_id_map
  |> Enum.map(fn {movie_id, _} ->
    {movie_id, predict_rating.(user_id, movie_id)}
  end)
  |> Enum.sort_by(&elem(&1, 1), :desc)
  |> Enum.take(n)
end

# Get recommendations for the first user
user_id = Enum.at(user_id_list, 0)
top_10_recommendations = get_top_n_recommendations.(user_id, 10)

# Prepare data for visualization
recommendation_data = Enum.map(top_10_recommendations, fn {movie_id, rating} ->
  %{movie_id: to_string(movie_id), predicted_rating: rating}
end)

# Create the visualization
Vl.new(width: 400, height: 300)
|> Vl.data_from_values(recommendation_data)
|> Vl.mark(:bar)
|> Vl.encode_field(:x, "movie_id", type: :nominal, title: "Movie ID")
|> Vl.encode_field(:y, "predicted_rating", type: :quantitative, title: "Predicted Rating")
|> Vl.encode_field(:color, "predicted_rating", type: :quantitative)
|> Vl.title("Top 10 Movie Recommendations for User #{user_id}")

```
